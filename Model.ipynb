{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNO0lPeBP4Af4k+wqLUiqZE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MS1997/Apparent-personality-analysis-using-videos/blob/master/Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbfwLtHJ-Ucc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the required packages \n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "import shutil\n",
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "from keras.layers import Input, TimeDistributed, Conv2D, BatchNormalization, LSTM, Flatten, MaxPool2D, Dense, Dropout, concatenate\n",
        "from keras.models import Model, load_model\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28o_Vicn-Mrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mounting the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYzOv7I21T4O",
        "colab_type": "text"
      },
      "source": [
        "Getting the Train, Validation and Test annotations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1MHcJlNzT19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with ZipFile('gdrive/My Drive/train-annotation.zip') as zf:\n",
        "    zf.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-sMwA_CNNFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with ZipFile('gdrive/My Drive/val-annotation-e.zip') as zf:\n",
        "    zf.extractall(pwd=b'') # password can be found on the First Impressions challenge website "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34C6YuOV8UAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with ZipFile('gdrive/My Drive/test-annotation-e.zip') as zf:\n",
        "    zf.extractall(pwd=b'') # password can be found on the First Impressions challenge website "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RptrgzuDyiVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# *************** Extracting Training images frame for all Videos from the drive *********************\n",
        "for i in range(1,7):\n",
        "  print('Entering folder: ',i)\n",
        "  with ZipFile(f'gdrive/My Drive/frames_{i}.zip') as zf:\n",
        "    zf.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXTJaoTC_a5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# *************** Extracting Validation images frame for all Videos from the drive *********************\n",
        "for i in range(1,3):\n",
        "  print('Entering folder: ',i)\n",
        "  with ZipFile(f'gdrive/My Drive/val_frames_{i}.zip') as zf:\n",
        "    zf.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GWTiBhU9gt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# *************** Extracting Test image frames for all Videos from the drive *********************\n",
        "with ZipFile(f'gdrive/My Drive/test_frames.zip') as zf:\n",
        "  zf.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka4ceSH40IuN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# *************** Extracting Training audio features for all Videos from the drive *********************\n",
        "for i in range(1,7):\n",
        "  print('Entering folder: ',i)\n",
        "  with ZipFile(f'gdrive/My Drive/aud_{i}.zip') as zf:\n",
        "    zf.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDcE4Ddogglx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5def3b45-42aa-4039-9ebf-e056c3d16771"
      },
      "source": [
        "# *************** Extracting Validation audio features for all Videos from the drive *********************\n",
        "for i in range(1,3):\n",
        "  print('Entering folder: ',i)\n",
        "  with ZipFile(f'gdrive/My Drive/aud_val_{i}.zip') as zf:\n",
        "    zf.extractall()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entering folder:  1\n",
            "Entering folder:  2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8rK-XXG85o2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# *************** Extracting Test audio features for all Videos from the drive *********************\n",
        "with ZipFile(f'gdrive/My Drive/aud_test.zip') as zf:\n",
        "  zf.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgwD5m-UACvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Number of videos in training data: ', len(os.listdir('frames'))) \n",
        "print('Number of videos in validation data: ', len(os.listdir('val_frames'))) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mEQyaJjguEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cross checking with audio \n",
        "print('Number of videos in training data: ', len(os.listdir('output'))) \n",
        "print('Number of videos in validation data: ', len(os.listdir('output_val'))) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov_MAuUl0cxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h = w = 150 # Height and Width of the Image\n",
        "c = 3 # Number of Channels\n",
        "time_steps = 15 # Frames extracted from the video \n",
        "aud_ft = 68 # Number of Audio features extracted from each non overlapping frame "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK8EXH0W2iFz",
        "colab_type": "text"
      },
      "source": [
        "We remove all data for those videos which have less than 15 non overlapping audio frames."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZOx0-uOimwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = []\n",
        "for i in os.listdir('output'):\n",
        "  data = pd.read_csv('/content/output/'+i,header = None) # Change here for validation and test sets \n",
        "  if data.shape[0] !=15:\n",
        "    l.append(i)\n",
        "for i in l:\n",
        "  name = i.split('.wav_st.csv')[0]\n",
        "  shutil.rmtree('frames/'+name)\n",
        "  os.remove('output/'+i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy5spyX-z_rk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generator function to produce mini batches of the data \n",
        "def get_batches(flag = 'train', b_size = 16):\n",
        "  count = 0 # counter variable \n",
        "\n",
        "  if flag == 'validation': # val set\n",
        "    path_ = 'val_frames/' # Path to validation data \n",
        "    anot = pd.read_pickle('annotation_validation.pkl') # Getting the validation scores \n",
        "    path_aud = 'output_val'  # Path to validation audio features \n",
        "\n",
        "  else: # train\n",
        "    path_ = 'frames/' # Path to train data \n",
        "    anot = pd.read_pickle('annotation_training.pkl') # Getting the train scores \n",
        "    path_aud = 'output'  # Path to train audio features \n",
        "    \n",
        "  data = os.listdir(path_) # list of all videos \n",
        "  random.shuffle(data)\n",
        "\n",
        "  # looping over all videos\n",
        "  while count < len(data): \n",
        "\n",
        "    all_frames = np.empty((0,time_steps,h,w,c)) # numpy array of batch of videos \n",
        "    labels = np.empty((0,5)) # numpy array to contain the 5 personality scores\n",
        "    aud_2 = np.empty((0,time_steps,aud_ft))  # numpy array to contain the audio features \n",
        "    \n",
        "    if (count + b_size) <= len(data): \n",
        "      batch_size = b_size\n",
        "    else: \n",
        "      batch_size = len(data) % b_size # incase when len(data) is not a multiple of batch_size \n",
        "\n",
        "\n",
        "     for i in range(batch_size):\n",
        "       # getting names of all image frames in folder for i th video \n",
        "      f_name = os.listdir(path_ + data[count])\n",
        "      # sorting the image frame names sequentially\n",
        "      f_name.sort(key= lambda x: int(re.findall(r'[_][\\d]+',x)[0].split('_')[1]))  \n",
        "      frames_1 = [] # list to contain array of all image farmes of the ith video\n",
        "      for j in f_name: # looping over all frames in the ith video\n",
        "        img = cv2.imread(path_ +data[count] +'/'+j)\n",
        "        frames_1.append(img) # appending each frame array\n",
        "  \n",
        "      # stacking all frames in the batch after scaling each frame \n",
        "      all_frames = np.vstack((all_frames,(np.array(frames_1)/255)[np.newaxis,...])) \n",
        "      \n",
        "    \n",
        "      # extracting the labels\n",
        "      l = np.array([anot['extraversion'][data[count]+'.mp4'],anot['neuroticism'][data[count]+'.mp4'],anot['agreeableness'][data[count]+'.mp4'],anot['conscientiousness'][data[count]+'.mp4'],anot['openness'][data[count]+'.mp4']])\n",
        "      labels = np.vstack((labels,l[np.newaxis,...]))\n",
        "      \n",
        "      # getting audio features\n",
        "      aud = pd.read_csv(f'{path_aud}/{data[count]}.wav_st.csv',header=None)\n",
        "      aud_1 = np.array(aud) # flattened audio features \n",
        "      # combining audio features of the batch \n",
        "      aud_2 = np.vstack((aud_2,aud_1[np.newaxis,...]))\n",
        "\n",
        "      count += 1\n",
        "\n",
        "# after every epoch the counter must start again \n",
        "    if count >= len(data): \n",
        "      count = 0\n",
        "      random.shuffle(data)\n",
        "      \n",
        "    yield [all_frames,aud_2], labels  # should yield audio and visual input of the model in one list \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYKh0KuMAlxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Making objects for the train and validation generator\n",
        "train_batches = get_batches(flag = 'train', b_size = 8)\n",
        "val_batches = get_batches(flag = 'validation', b_size = 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v7Dpp336Fsx",
        "colab_type": "text"
      },
      "source": [
        "<h1> Defining the Model using Keras Functional API </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxNym7jTH4oR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model Architecture\n",
        "\n",
        "# Dense layer for audio data \n",
        "input_aud = Input(shape=(time_steps, aud_ft))\n",
        "aud_mod = TimeDistributed(Dense(32, activation = 'relu'))(input_aud)\n",
        "\n",
        "\n",
        "# CNN-LSTM network \n",
        "\n",
        "# Convolutional model \n",
        "input_img = Input(shape=(time_steps, h, w, c)) \n",
        "\n",
        "conv_model = TimeDistributed(Conv2D(64, (3,3), padding='same', activation='relu') )(input_img)\n",
        "conv_model = TimeDistributed(Conv2D(64, (3,3), padding='same', activation='relu') )(conv_model)\n",
        "conv_model = TimeDistributed(BatchNormalization())(conv_model) # applying activation before BN\n",
        "conv_model = TimeDistributed(MaxPool2D(pool_size=(2,2),padding='same',strides=(2,2)))(conv_model) \n",
        "# max pooling with stride of two, it will move with two steps and then take the max \n",
        "\n",
        "conv_model = TimeDistributed(Conv2D(128, (3,3), padding='same', activation='relu') )(conv_model)\n",
        "conv_model = TimeDistributed(Conv2D(128, (3,3), padding='same', activation='relu') )(conv_model)\n",
        "conv_model = TimeDistributed(BatchNormalization())(conv_model) \n",
        "conv_model = TimeDistributed(MaxPool2D(pool_size=(2,2),padding='same'))(conv_model) #,strides=(2,2)\n",
        "\n",
        "conv_model = TimeDistributed(Conv2D(256, (3,3), padding='same', activation='relu') )(conv_model)\n",
        "conv_model = TimeDistributed(Conv2D(256, (3,3), padding='same', activation='relu') )(conv_model)\n",
        "conv_model = TimeDistributed(BatchNormalization())(conv_model) \n",
        "conv_model = TimeDistributed(MaxPool2D(pool_size=(2,2),padding='same'))(conv_model)\n",
        "\n",
        "\n",
        "# Flatten the output \n",
        "conv_model = TimeDistributed(Flatten())(conv_model)\n",
        "\n",
        "\n",
        "# concatenating audio features with image features \n",
        "comb_model = concatenate([aud_mod, conv_model]) \n",
        "\n",
        "# LSTM \n",
        "# For LSTMs the input has to be 3 dimensional, (number of sample, number of time_steps, number of features)\n",
        "lstm = LSTM(128, return_sequences=True,dropout=0.2,recurrent_dropout=0.2)(comb_model)\n",
        "# return_sequences = True for stacked LSTMs to provide one output for each time step to get a 3 dimensional array as output \n",
        "lstm = LSTM(128, return_sequences=False,dropout=0.2,recurrent_dropout=0.2)(lstm)\n",
        "\n",
        "# Feedforward output layers\n",
        "final_part = Dense(64,activation='relu')(lstm)\n",
        "final_part  = Dropout(0.5)(final_part )   \n",
        "output  = Dense(5,activation='sigmoid')(final_part ) # Sigmoid because we want each output to be between 0 and 1 \n",
        "# But the sum need not be equal to 1 unlike softmax \n",
        "\n",
        "model = Model([input_img,input_aud],output)  #[input_1,input_2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9geU0l88bqGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras.backend as k\n",
        "def mean_acc(y_true, y_pred):\n",
        "    diff = k.abs(y_true - y_pred)\n",
        "    return k.mean(1-diff)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xROWhYRus0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()\n",
        "plot_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p14oga8iQjz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the Model \n",
        "model.compile(loss= 'mse', optimizer= Adam(0.00001),metrics=[mean_acc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVzg4tpgAt5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training the model \n",
        "history_1 = model.fit_generator(train_batches,validation_data= val_batches, epochs=20,steps_per_epoch= int((6000-48)/8),validation_steps= int((2000-11)/8) )#,callbacks= callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4Vsf1xEetm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the history.history dict to a pandas DataFrame:     \n",
        "hist_df = pd.DataFrame(history_1.history) \n",
        "\n",
        "# and save to csv: \n",
        "hist_csv_file = '/content/gdrive/My Drive/hist_aud_vid_2.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABeuT9RceuQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('gdrive/My Drive/mod_aud_vid.h5') # Saving the model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3TFNPFzYUUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('gdrive/My Drive/mod_aud_vid.h5',custom_objects={'mean_acc': mean_acc}) # load custom metrics using this dictionary "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ixQHBtkByAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generator function for the test data set \n",
        "count = 0 # counter variable \n",
        "\n",
        "path_ = 'test_frames/' # Path to test data \n",
        "anot = pd.read_pickle('annotation_test.pkl') # Getting the test scores \n",
        "path_aud = 'output_test' # Getting the Test audio features \n",
        "\n",
        "data = os.listdir(path_)\n",
        "\n",
        "labels = []\n",
        "pred =[]\n",
        "mean_acc_test = []\n",
        "\n",
        "# looping over all test videos\n",
        "while count < len(data):  \n",
        "    \n",
        "  f_name = os.listdir(path_ + data[count]) # getting names of all frames in video folder\n",
        "  f_name.sort(key= lambda x: int(re.findall(r'[_][\\d]+',x)[0].split('_')[1])) # sorting the frame names sequentially \n",
        "\n",
        "  frames_1 = [] # list to contain array of all farmes\n",
        "  for j in f_name: # looping over all frames in a video\n",
        "      img = cv2.imread(path_ +data[count] +'/'+j)\n",
        "      frames_1.append(img) # appending each frame array\n",
        "  frames_1 = np.array(frames_1)/255\n",
        "\n",
        "  # extracting the labels\n",
        "  l = np.array([anot['extraversion'][data[count]+'.mp4'],anot['neuroticism'][data[count]+'.mp4'],anot['agreeableness'][data[count]+'.mp4'],anot['conscientiousness'][data[count]+'.mp4'],anot['openness'][data[count]+'.mp4']])\n",
        "  labels.append(l)\n",
        "      \n",
        "  # getting audio features\n",
        "  aud = pd.read_csv(f'{path_aud}/{data[count]}.wav_st.csv',header=None)\n",
        "  aud_1 = np.array(aud) \n",
        "  \n",
        "  p = model.predict([frames_1[np.newaxis,...],aud_1[np.newaxis,...]])\n",
        "  pred.append(p)\n",
        "  \n",
        "  mean_acc_test.append(np.mean(1-np.absolute(l-p)))\n",
        "  count += 1\n",
        "  \n",
        "  if count%10 == 0:\n",
        "    print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0kApit4ZMSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.mean(mean_acc_test) # Getting the Total Mean Accuracy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BTiJd6NYyDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to get test Mean accuracy of each trait \n",
        "def each_trait_acc(j):  \n",
        "  trait_label = [i[j] for i in labels]\n",
        "  trait_pred = [i[0][j] for i in pred]\n",
        "  return np.mean(1-np.abs(np.array(trait_label)-np.array(trait_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lQEOWlAbyxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "each_trait_acc(0) # Mean Accuracy for Extraversion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbYXDs6Waacy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "each_trait_acc(1) # Mean Accuracy for Neuroticism"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIwGdClSajgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "each_trait_acc(2) # Mean Accuracy for Agreeablenss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCrIqkCvajxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "each_trait_acc(3) # Mean Accuracy for Conscientiousness"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuJz-0eDaj_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "each_trait_acc(4) # Mean Accuracy for Openenss"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}